{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate TFRecord.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPk2pbEYwnf37Aty6oUXyxc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProtossDragoon/paper_implementation_and_testing_tf2/blob/main/utils/Generate_TFRecord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWmU_9K2tWCi"
      },
      "source": [
        "# Generate TFRecord\n",
        "\n",
        "## Author\n",
        "\n",
        "name : Janghoo Lee <br>\n",
        "github : https://github.com/ProtossDragoon <br>\n",
        "contact : dlwkdgn1@naver.com <br>\n",
        "circle : https://github.com/sju-coml <br>\n",
        "organization : https://web.deering.co/ <br>\n",
        "published date : June, 2021\n",
        "\n",
        "\n",
        "## Related Notebook\n",
        "\n",
        "[Notebooks](https://github.com/ProtossDragoon/paper_implementation_and_testing_tf2/tree/main/notebooks)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiCtnVJZtV3p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FcztBRNa5Au"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSJsL2FStS0y",
        "outputId": "37213bf2-190d-44c0-efeb-67819811bf9e"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUgp9ccsbAUA"
      },
      "source": [
        "import os, sys\n",
        "from tqdm.notebook import tqdm as tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_0n8J6KbDBB"
      },
      "source": [
        "## Google Drive / Git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt06_IrzeV-W",
        "outputId": "8c2007ee-eb5e-4718-b508-cfadba8d46d0"
      },
      "source": [
        "#!rm -r /content/gdrive/\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-6jSRBSbDzl"
      },
      "source": [
        "HOME_DIR = \"/content/gdrive/MyDrive\"\n",
        "WS = os.path.join(HOME_DIR, \"ColabWorkspace\")\n",
        "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
        "DATA_INDEX_DIR = os.path.join(DATA_DIR, 'index')\n",
        "DATA_TFRECORD_DIR = os.path.join(DATA_DIR, 'tfrecord')\n",
        "\n",
        "GIT_REPO_NAME = 'paper_implementation_and_testing_tf2'\n",
        "GIT_WS = os.path.join(WS, GIT_REPO_NAME)\n",
        "\n",
        "GIT_BRANCH = 'master'\n",
        "GIT_USERNAME = None # Add herea\n",
        "GIT_EMAIL = None\n",
        "GIT_PASSWORD = None # Add here"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYialtbGbH7L",
        "outputId": "17e151f8-ff29-4a0b-ecc0-061aecd5805a"
      },
      "source": [
        "!mkdir -p {WS}\n",
        "%cd {WS}\n",
        "!git clone https://github.com/ProtossDragoon/{GIT_REPO_NAME}.git\n",
        "%cd {GIT_WS}\n",
        "!git config --global user.name {GIT_USERNAME}\n",
        "!git config --global user.email {GIT_EMAIL}\n",
        "!git checkout -b {GIT_BRANCH}\n",
        "!git checkout {GIT_BRANCH}\n",
        "!git pull origin {GIT_BRANCH}\n",
        "!git push origin {GIT_BRANCH}\n",
        "!git branch\n",
        "!git branch --set-upstream-to origin/{GIT_BRANCH}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/ColabWorkspace\n",
            "fatal: destination path 'paper_implementation_and_testing_tf2' already exists and is not an empty directory.\n",
            "/content/gdrive/MyDrive/ColabWorkspace/paper_implementation_and_testing_tf2\n",
            "fatal: A branch named 'master' already exists.\n",
            "Switched to branch 'master'\n",
            "fatal: Couldn't find remote ref master\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "  list\u001b[m\n",
            "  main\u001b[m\n",
            "* \u001b[32mmaster\u001b[m\n",
            "  resnet\u001b[m\n",
            "  tftrt\u001b[m\n",
            "  unet\u001b[m\n",
            "error: the requested upstream branch 'origin/master' does not exist\n",
            "hint: \n",
            "hint: If you are planning on basing your work on an upstream\n",
            "hint: branch that already exists at the remote, you may need to\n",
            "hint: run \"git fetch\" to retrieve it.\n",
            "hint: \n",
            "hint: If you are planning to push out a new local branch that\n",
            "hint: will track its remote counterpart, you may want to use\n",
            "hint: \"git push -u\" to set the upstream config as you push.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDqituO2gDrs"
      },
      "source": [
        "# Convert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDMRW5LJf-mE"
      },
      "source": [
        "## Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5HwstNAiUfI",
        "outputId": "0adb5633-84a6-4364-e3b3-992de2860002"
      },
      "source": [
        "DATASETNAME = \"aihubpedestrian\" #@param {type:\"string\"}\n",
        "TXT_FILE_DIR = os.path.join(DATA_INDEX_DIR, DATASETNAME.upper())\n",
        "TXT_FILE_NAME = 'train' #@param ['train', 'val', 'test']\n",
        "TXT_FILE_NAME += '.txt'\n",
        "TXT_FILE_FULLPATH = os.path.join(TXT_FILE_DIR, TXT_FILE_NAME)\n",
        "\n",
        "print(\"Indexfile generation result save '{}' at {}\".format(TXT_FILE_NAME, TXT_FILE_FULLPATH))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexfile generation result save 'train.txt' at /content/gdrive/MyDrive/data/index/AIHUBPEDESTRIAN/train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLC0tc91f9x5",
        "outputId": "355c45d9-aedd-4af1-a64e-8bcc6ad4aa4a"
      },
      "source": [
        "DATASETNAME = \"aihubpedestrian\" #@param {type:\"string\"}\n",
        "TFRECORD_FILE_DIR = os.path.join(DATA_TFRECORD_DIR, DATASETNAME.upper())\n",
        "TFRECORD_FILE_NAME = 'train' #@param ['train', 'val', 'test']\n",
        "TFRECORD_FILE_NAME += '.tfrecord'\n",
        "TFRECORD_FILE_FULLPATH = os.path.join(TFRECORD_FILE_DIR, TFRECORD_FILE_NAME)\n",
        "\n",
        "print(\"TFRecord Conversion result save '{}' at {}\".format(TFRECORD_FILE_NAME, TFRECORD_FILE_FULLPATH))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFRecord Conversion result save 'train.tfrecord' at /content/gdrive/MyDrive/data/tfrecord/AIHUBPEDESTRIAN/train.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goJY6Ntvh9Og"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF_jY1lvh9Dz"
      },
      "source": [
        "## Generate Index file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMXIVd_Hd-EO"
      },
      "source": [
        "# Debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imz_UXMWeKMC",
        "outputId": "23f79dae-286d-4f87-8e39-b6b39919186b"
      },
      "source": [
        "DATASET_DIR_CAMVID = os.path.join(DATA_DIR, 'camvid')\n",
        "DATASET_TRAIN_X_DIR_CAMVID = os.path.join(DATASET_DIR_CAMVID, 'train')\n",
        "DATASET_TRAIN_Y_DIR_CAMVID = os.path.join(DATASET_DIR_CAMVID, 'trainannot')\n",
        "DATASET_VAL_X_DIR_CAMVID = os.path.join(DATASET_DIR_CAMVID, 'val')\n",
        "DATASET_VAL_Y_DIR_CAMVID = os.path.join(DATASET_DIR_CAMVID, 'valannot')\n",
        "DATASET_TEST_X_DIR_CAMVID = os.path.join(DATASET_DIR_CAMVID, 'test')\n",
        "DATASET_TEST_Y_DIR_CAMVID = os.path.join(DATASET_DIR_CAMVID, 'testannot')\n",
        "\n",
        "%cd {WS}\n",
        "%ls -al"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/ColabWorkspace\n",
            "total 20\n",
            "drwx------  2 root root 4096 Jun 22 02:12 \u001b[0m\u001b[01;34malbumentations\u001b[0m/\n",
            "drwx------  2 root root 4096 Jun 25 02:12 \u001b[01;34m{BACKUP_DIR}\u001b[0m/\n",
            "drwx------  2 root root 4096 Jun 22 02:12 \u001b[01;34mefficientnet\u001b[0m/\n",
            "drwx------ 14 root root 4096 May 25 05:07 \u001b[01;34mpaper_implementation_and_testing_tf2\u001b[0m/\n",
            "drwx------  2 root root 4096 Jun 22 02:12 \u001b[01;34msegmentation_models\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FuBBpvbeKhB",
        "outputId": "a8bcb66f-ddda-453c-d813-817f08c28163"
      },
      "source": [
        "DATASET_DIR_PEDESTRIAN = os.path.join(DATA_DIR, 'aihubsidewalk')\n",
        "DATASET_TRAIN_TXT_PEDESTRIAN = os.path.join(DATASET_DIR_PEDESTRIAN, 'train.txt')\n",
        "DATASET_VALID_TXT_PEDESTRIAN = os.path.join(DATASET_DIR_PEDESTRIAN, 'val.txt')\n",
        "DATASET_TEST_TXT_PEDESTRIAN = os.path.join(DATASET_DIR_PEDESTRIAN, 'test.txt')\n",
        "\n",
        "%cd {WS}\n",
        "%ls -al"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/ColabWorkspace\n",
            "total 20\n",
            "drwx------  2 root root 4096 Jun 22 02:12 \u001b[0m\u001b[01;34malbumentations\u001b[0m/\n",
            "drwx------  2 root root 4096 Jun 25 02:12 \u001b[01;34m{BACKUP_DIR}\u001b[0m/\n",
            "drwx------  2 root root 4096 Jun 22 02:12 \u001b[01;34mefficientnet\u001b[0m/\n",
            "drwx------ 14 root root 4096 May 25 05:07 \u001b[01;34mpaper_implementation_and_testing_tf2\u001b[0m/\n",
            "drwx------  2 root root 4096 Jun 22 02:12 \u001b[01;34msegmentation_models\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR14OFTTd-Se"
      },
      "source": [
        "# classes for data loading and preprocessing\n",
        "import abc\n",
        "class SegmentationDataset(abc.ABC):\n",
        "    \"\"\"Segmentation Dataset. Read images, apply augmentation and preprocessing transformations.\n",
        "       Inheritance this class and implement fill_data method.\n",
        "       - Inside of fill_data method, self.images_fps and self.mask_fps should be filled.\n",
        "       - If you have RGB colorized masks, put {(int)classid: <tuple>(r,g,b)} shaped dictionary at self.class_id_to_rgb.\n",
        "       \n",
        "       \n",
        "       Args:\n",
        "            class_ids (list): values of classes ids       \n",
        "            augmentation (albumentations.Compose): data transfromation pipeline \n",
        "                (e.g. flip, scale, etc.)\n",
        "            preprocessing (albumentations.Compose): data preprocessing \n",
        "                (e.g. noralization, shape manipulation, etc.)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, class_ids=None, augmentation=None, preprocessing=None, resizing=None):\n",
        "\n",
        "        # self.images_fps = user implementation \n",
        "        # self.masks_fps = user implementation        \n",
        "        # self.class_id_to_rgb = user implementation\n",
        "        self.class_ids = class_ids\n",
        "        self.interested_class_id_rgb = None\n",
        "\n",
        "        # func*\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "        self.resizing = resizing\n",
        "\n",
        "        print('augmentation : {} -> {}'.format(type(augmentation), type(self.augmentation)))\n",
        "        print('preprocessing : {} -> {}'.format(type(preprocessing), type(self.preprocessing)))\n",
        "        print('resizing : {} -> {}'.format(type(resizing), type(self.resizing)))\n",
        "\n",
        "        # mode\n",
        "        self.mode = 'tf.keras.Sequence' # or tf.data.Dataset\n",
        "\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def fill_data(self):\n",
        "        \"\"\"Implement this mehtod and fill these member elements\n",
        "\n",
        "        Member to elements:\n",
        "            image_fps (str): file path to images\n",
        "            masks_fps (str): file path to segmentation masks\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def _readmask(self, i, class_id_to_rgb=None):\n",
        "        \"\"\"extract certain classes from mask (e.g. cars)\n",
        "        \"\"\"\n",
        "\n",
        "        if hasattr(self, 'class_id_to_rgb') and (class_id_to_rgb is None):\n",
        "            # If overrided class implemented self.class_id_to_rgb\n",
        "            class_id_to_rgb = self.class_id_to_rgb\n",
        "\n",
        "        if class_id_to_rgb is None:\n",
        "            mask = cv2.imread(self.masks_fps[i], cv2.IMREAD_GRAYSCALE)\n",
        "            masks = [(mask == v) for v in self.class_ids]\n",
        "        else:\n",
        "            self.interested_class_id_rgb = {}\n",
        "            mask = cv2.imread(self.masks_fps[i])\n",
        "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "            for k, v in class_id_to_rgb.items():\n",
        "                if k in self.class_ids:\n",
        "                    self.interested_class_id_rgb[k] = v\n",
        "\n",
        "            ## debug\n",
        "            # print(self.masks_fps[i]) ## debug\n",
        "            # print(self.images_fps[i]) ## debug\n",
        "            # print(image.shape, mask.shape) ## debug\n",
        "\n",
        "            masks = []\n",
        "            for class_id, colors in self.interested_class_id_rgb.items():\n",
        "                # e.g. one class has two color {2: [(255, 128, 0), (255, 64, 0)]}\n",
        "                if len(np.array(colors).shape) == 2:\n",
        "                    temp_mask = []\n",
        "                    for color in np.array(colors):\n",
        "                        temp_mask.append(np.all(mask == color, axis=-1))    \n",
        "                    masks.append(np.logical_or.reduce(temp_mask))\n",
        "                else:\n",
        "                    ## debug\n",
        "                    # print('---\\n', colors) ## debug\n",
        "                    # print(np.all(mask == colors, axis=-1)) ## debug\n",
        "                    # print('---') ## debug\n",
        "                    # plt.figure() ## debug\n",
        "                    # plt.imshow(np.all(mask == colors, axis=-1)) ## debug\n",
        "                    ## debug\n",
        "                    masks.append(np.all(mask == colors, axis=-1))\n",
        "\n",
        "        mask = np.stack(masks, axis=-1).astype('int')\n",
        "\n",
        "        ## debug\n",
        "        # print('mask max : {}, min : {}, type : {}'.format(mask.max(), mask.min(), mask.dtype)) ## debug\n",
        "\n",
        "        # add background if mask is not binary\n",
        "        if mask.shape[-1] != 1:\n",
        "            background = 1 - mask.sum(axis=-1, keepdims=True)\n",
        "            mask = np.concatenate((mask, background), axis=-1)\n",
        "\n",
        "        ## debug\n",
        "        # print('mask max : {}, min : {}, type : {}'.format(mask.max(), mask.min(), mask.dtype)) ## debug\n",
        "\n",
        "        return mask.astype('float')\n",
        "\n",
        "\n",
        "    def _preprocessing_tf(self, image, mask):\n",
        "        ret = self.preprocessing(image=image, mask=mask)\n",
        "        image = ret['image']\n",
        "        mask = ret['mask']\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "    @tf.function(input_signature=(tf.TensorSpec(shape=[None, None, None], dtype=tf.uint8), \n",
        "                                  tf.TensorSpec(shape=[None, None, None], dtype=tf.uint8),\n",
        "                                  tf.TensorSpec(shape=[], dtype=tf.bool),))\n",
        "    def _preprocessing_fn(self, image, mask, preprocessing_exist):\n",
        "        #tf.print('self._preprocessing_exist :', self._preprocessing_exist)\n",
        "        if preprocessing_exist: # branch type : <image> tf.uint8 -> tf.float32\n",
        "            #debugging code\n",
        "            #tf.print('preprocessing_fn / main branch / <image> val :', tf.math.reduce_min(image), '~', tf.math.reduce_max(image))\n",
        "            image = tf.cast(image, tf.float32)\n",
        "            #debugging code\n",
        "            #tf.print('preprocessing_fn / main branch / casting / <image> val :', tf.math.reduce_min(image), '~', tf.math.reduce_max(image))\n",
        "            image, mask = tf.numpy_function(func=self._preprocessing_tf, inp=[image, mask], Tout=[tf.float32, tf.uint8])\n",
        "            #debugging code\n",
        "            #tf.print('preprocessing_fn / main branch / casting / preprocessing / <image> val :', tf.math.reduce_min(image), '~', tf.math.reduce_max(image))\n",
        "            #tf.print('preprocessing_fn / main branch / casting / preprocessing / <image> tensorspec :', tf.TensorSpec.from_tensor(image))\n",
        "        else: # branch type : <image> tf.uint8 -> tf.float32\n",
        "            image = tf.cast(image, tf.float32)\n",
        "            #debugging code\n",
        "            #tf.print('preprocessing_fn / else branch / <image> val :',tf.math.reduce_min(image), '~', tf.math.reduce_max(image))\n",
        "            #tf.print('preprocessing_fn / else branch / <image> tensorspec :', tf.TensorSpec.from_tensor(image))\n",
        "\n",
        "        #debugging code\n",
        "        #tf.print('preprocessing_fn / <image> val :', tf.math.reduce_min(image), '~', tf.math.reduce_max(image))\n",
        "        #tf.print('preprocessing_fn / <image> tensorspec :', tf.TensorSpec.from_tensor(image))\n",
        "        \n",
        "        #categorical crossentropy loss function etc... wants float tensor, not uint8 tensor.\n",
        "        # <mask> tf.uint8 -> tf.uint8\n",
        "        mask = tf.cast(mask, tf.float32)\n",
        "        \n",
        "        return image, mask\n",
        "\n",
        "\n",
        "    def _resizing_tf(self, image, mask):\n",
        "        #debugging code\n",
        "        #print(image, mask)\n",
        "        #print(type(image), type(mask))\n",
        "        #tf.print(type(image), type(mask))\n",
        "\n",
        "        ret = self.resizing(image=image, mask=mask)\n",
        "        return ret\n",
        "\n",
        "\n",
        "    @tf.function(input_signature=(tf.TensorSpec(shape=[None, None, None], dtype=tf.uint8), \n",
        "                                  tf.TensorSpec(shape=[None, None, None], dtype=tf.uint8),\n",
        "                                  tf.TensorSpec(shape=[], dtype=tf.bool),))    \n",
        "    def _resizing_fn(self, image, mask, resizing_exist):\n",
        "        # <image> : tf.uint8\n",
        "        # <mask> : tf.uint8\n",
        "        if resizing_exist: # branch type : <image> tf.uint8 -> tf.uint8, <mask> tf.uint8 -> tf.uint8\n",
        "            # Do not remove py_function.\n",
        "            # does not work because tensorflow make static graph before runtime, tf.function check all kind of cases so it ends up with error.\n",
        "            image, mask = tf.py_function(func=self._resizing_tf, inp=[image, mask], Tout=[tf.float32, tf.uint8])\n",
        "            image = tf.cast(image, tf.uint8)\n",
        "            mask = tf.cast(mask, tf.uint8)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        #debugging code\n",
        "        #tf.print('resizing_fn / <image> val :', tf.math.reduce_min(image), '~', tf.math.reduce_max(image))\n",
        "        #tf.print('resizing_fn / <image> tensorspec :', tf.TensorSpec.from_tensor(image))\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "    def _readmask_tf(self, mask, class_id_to_rgb=None):\n",
        "        \"\"\"extract certain classes from mask (e.g. cars)\n",
        "        \"\"\"\n",
        "        if mask.shape[-1] == 1:\n",
        "            mask = np.squeeze(mask)\n",
        "\n",
        "        if hasattr(self, 'class_id_to_rgb') and (class_id_to_rgb is None):\n",
        "            # If overrided class implemented self.class_id_to_rgb\n",
        "            class_id_to_rgb = self.class_id_to_rgb\n",
        "\n",
        "        if class_id_to_rgb is None:\n",
        "            masks = [(mask == v).astype('int') for v in self.class_ids]\n",
        "        else:\n",
        "            self.interested_class_id_rgb = {}\n",
        "            for k, v in class_id_to_rgb.items():\n",
        "                if k in self.class_ids:\n",
        "                    self.interested_class_id_rgb[k] = v\n",
        "\n",
        "            masks = []\n",
        "            for class_id, colors in self.interested_class_id_rgb.items():\n",
        "                # e.g. one class has two color {2: [(255, 128, 0), (255, 64, 0)]}\n",
        "                if len(np.array(colors).shape) == 2:\n",
        "                    temp_mask = []\n",
        "                    for color in np.array(colors):\n",
        "                        temp_mask.append(np.all(mask == color, axis=-1).astype('int'))\n",
        "                    masks.append(np.logical_or.reduce(temp_mask))\n",
        "                else:\n",
        "\n",
        "                    ## debug\n",
        "                    # print('---\\n', colors) ## debug\n",
        "                    # print(np.all(mask == colors, axis=-1)) ## debug\n",
        "                    # print('---') ## debug\n",
        "                    \n",
        "                    ## debug\n",
        "                    # plt.figure() ## debug\n",
        "                    # plt.imshow(np.all(mask == colors, axis=-1)) ## debug\n",
        "\n",
        "                    masks.append(np.all(mask == colors, axis=-1))\n",
        "\n",
        "        ## debug\n",
        "        # print('mask max : {}, min : {}, type : {}'.format(mask.numpy().max(), mask.numpy().min(), mask.numpy().dtype)) ## debug\n",
        "\n",
        "        # mask = np.stack(masks, axis=-1).astype('int') ## temp\n",
        "        mask = tf.stack(masks, axis=-1) ## temp\n",
        "        mask = tf.cast(mask, tf.uint8) ## temp\n",
        "\n",
        "        # add background if mask is not binary\n",
        "        if mask.shape[-1] != 1:\n",
        "\n",
        "            # background = 1 - mask.sum(axis=-1, keepdims=True) ## temp\n",
        "            background = 1 - tf.math.reduce_sum(mask, axis=-1, keepdims=True) ## temp\n",
        "            \n",
        "            ## debug\n",
        "            # plt.figure() ## debug\n",
        "            # plt.title('background') ## debug\n",
        "            # plt.imshow(background.squeeze()) ## debug ## temp\n",
        "            # plt.imshow(background.numpy().squeeze(), vmax=1, vmin=0) ## debug ## temp\n",
        "            \n",
        "            ## debug\n",
        "            # print('background ({}) max : {}, min : {}, type : {}'.format(background.shape, background.max(), background.min(), background.dtype)) ## debug\n",
        "            \n",
        "            # mask = np.concatenate((mask, background), axis=-1) ## temp\n",
        "            background = tf.cast(background, tf.uint8) ## temp\n",
        "            mask = tf.concat((mask, background), axis=-1) ## temp\n",
        "\n",
        "            ## debug\n",
        "            # print('mask ({}) max : {}, min : {}, type : {}'.format(mask.shape, mask.max(), mask.min(), mask.dtype)) ## debug\n",
        "\n",
        "            ## debug\n",
        "            # plt.figure() ## debug\n",
        "            # plt.title('background-fromtensor') ## debug\n",
        "            # plt.imshow(mask[:,:,-1], vmax=1, vmin=0) ## debug ## temp\n",
        "            # plt.imshow(mask[:,:,-1], vmax=1, vmin=0) ## debug ## temp\n",
        "\n",
        "        ## debug\n",
        "        # print('mask max : {}, min : {}, type : {}'.format(mask.numpy().max(), mask.numpy().min(), mask.numpy().dtype)) ## debug\n",
        "\n",
        "        mask = tf.cast(mask, tf.uint8) ## temp\n",
        "        # mask = mask.astype('uint8') ## temp\n",
        "\n",
        "        return mask\n",
        "\n",
        "\n",
        "    def _augmentation_tf(self, image, mask):\n",
        "        ret = self.augmentation(image=image, mask=mask)\n",
        "        image = ret['image']\n",
        "        mask = ret['mask']\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "    @tf.function(input_signature=(tf.TensorSpec(shape=[], dtype=tf.string), \n",
        "                                  tf.TensorSpec(shape=[], dtype=tf.string),\n",
        "                                  tf.TensorSpec(shape=[], dtype=tf.bool),))    \n",
        "    def _read_and_augmentation_fn(self, images_fps, masks_fps, augmentation_exist):\n",
        "        # <images_fps> : tf.string\n",
        "        # <masks_fps> : tf.string\n",
        "        print('Retracing!')\n",
        "\n",
        "        image = tf.io.read_file(images_fps)\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "        image = tf.image.convert_image_dtype(image, tf.uint8) \n",
        "        # NOTE: Converting integer types to floating point types returns normalized floating point values in the range [0, 1)\n",
        "        # NOTE: See more, https://www.tensorflow.org/api_docs/python/tf/image/convert_image_dtype\n",
        "\n",
        "        mask = tf.io.read_file(masks_fps)\n",
        "        mask = tf.image.decode_png(mask, channels=0) # Select number of channel automatically.\n",
        "        mask = tf.image.convert_image_dtype(mask, tf.uint8)\n",
        "        mask = tf.py_function(func=self._readmask_tf, inp=[mask], Tout=tf.uint8)\n",
        "\n",
        "        if augmentation_exist:\n",
        "            image, mask = tf.numpy_function(func=self._augmentation_tf, inp=[image, mask], Tout=[tf.uint8, tf.uint8])        \n",
        "\n",
        "        #debugging code\n",
        "        #tf.print('read_and_augmentation_fn / <image> val :', tf.math.reduce_min(image), '~', tf.math.reduce_max(image))\n",
        "        #tf.print('read_and_augmentation_fn / <image> tensorspec :', tf.TensorSpec.from_tensor(image))\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "    def get_tf_dataset(self):\n",
        "        assert self.mode == 'tf.data.Dataset', 'Current mode : {}, If you want to use this method, implement self.images_dataset and self.masks_dataset'.format(self.mode)\n",
        "        images_dataset = self.images_dataset\n",
        "        masks_dataset = self.masks_dataset\n",
        "        self._augmentation_exist = tf.constant(True if self.augmentation is not None else False, dtype=tf.bool, shape=())\n",
        "        self._resizing_exist = tf.constant(True if self.resizing is not None else False, dtype=tf.bool, shape=())\n",
        "        self._preprocessing_exist = tf.constant(True if self.preprocessing is not None else False, dtype=tf.bool, shape=())\n",
        "\n",
        "        tf.print('augmentation :', self._augmentation_exist)\n",
        "        tf.print('resizing :', self._resizing_exist)\n",
        "        tf.print('preprocessing :', self._preprocessing_exist)\n",
        "\n",
        "        n = tf.data.AUTOTUNE\n",
        "        if n != tf.data.AUTOTUNE:\n",
        "            print('Warning : parallel call is not AUTOTUNE. It could make pipeline slow.')\n",
        "\n",
        "        dataset = tf.data.Dataset.zip((images_dataset, masks_dataset)).map(\n",
        "            lambda im, mask: self._read_and_augmentation_fn(im, mask, self._augmentation_exist), num_parallel_calls=n).map(\n",
        "                lambda im, mask: self._resizing_fn(im, mask, self._resizing_exist), num_parallel_calls=n).map(\n",
        "                    lambda im, mask: self._preprocessing_fn(im, mask, self._preprocessing_exist), num_parallel_calls=n)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "\n",
        "    def _getitem_keras(self, i):\n",
        "        # read data\n",
        "        image = cv2.imread(self.images_fps[i])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # extract certain classes from mask (e.g. cars)\n",
        "        mask = self._readmask(i)\n",
        "                \n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "        \n",
        "        # apply final resizing\n",
        "        if self.resizing:\n",
        "            image_dt = image.dtype\n",
        "            mask_dt = mask.dtype\n",
        "            image, mask = self.resizing(image=image, mask=mask)\n",
        "            image = image.numpy().astype(image_dt)\n",
        "            mask = mask.numpy().astype(mask_dt)\n",
        "\n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "    def __getitem__(self, i): # batch\n",
        "        if self.mode == 'tf.keras.Sequence':\n",
        "            return self._getitem_keras(i)\n",
        "        else:\n",
        "            print('tf.data.Dataset is not a subscribable object.')\n",
        "            raise NotImplementedError\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images_fps)\n",
        "\n",
        "def resizing(model_input_w_for_train, model_input_h_for_train):\n",
        "    def wrapper(image=None, mask=None):\n",
        "        image = tf.image.resize(image, [model_input_h_for_train, model_input_w_for_train], method='bilinear', antialias=True)\n",
        "        image = tf.clip_by_value(image, 0.0, 255.0)\n",
        "        mask = tf.image.resize(mask, [model_input_h_for_train, model_input_w_for_train], method='nearest')\n",
        "        return image, mask\n",
        "    return wrapper"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZftjr6zeAgF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}